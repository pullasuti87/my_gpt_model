# my_chatgpt (simple transformerLM)

my attempt to understand language models a little better,
relies heavily on the _Building Transformer Models with Attention_ book
a_nd _Andrej Karpathy's_ transformer implementations

- self-attention
- multi-head attention
- position embeddings
- tiktoken
- uses data.txt -> using finnish text

## needs

- python3
- pytorch
- tiktoken

[check out](notes.md)


